# PDF技術文書 翻訳システム

鉄鋼業設備技術文書の英語→日本語翻訳に特化したPDF翻訳アプリケーション。Apple Silicon (M4 Pro) に最適化されています。

## 主な機能

- **PDF技術文書の翻訳**: 英語の技術文書を日本語に翻訳
- **3段階の品質設定**: 高品質(Qwen3-14B)、バランス(Qwen2.5-7B)、高速(Qwen2.5-3B)
- **用語集管理**: 専門用語の翻訳を統一し、再起動後も保持
- **LLM校正機能**: 翻訳の正確性をLLMで検証・修正
- **再翻訳機能**: 品質設定を変更して再翻訳可能
- **ページ単位表示**: PDFビューアと翻訳結果を並列表示
- **ダウンロード機能**: 原文のみ、翻訳のみ、両方を選択可能

## 技術スタック

### Frontend
- React 18
- TypeScript
- Vite
- Axios
- react-pdf

### Backend
- Python 3.11+
- FastAPI
- PyTorch (MPS対応)
- Transformers (Hugging Face)
- pdfplumber

## 必要な環境

- macOS (Apple Silicon推奨)
- Python 3.8以上
- Node.js 16以上
- 64GB RAM推奨（最低32GB）

## クイックスタート

### 1. 初回セットアップ

```bash
# リポジトリをクローン
git clone https://github.com/babasaki-r/PDF-Translation-App.git
cd PDF_Translation_App

# セットアップスクリプトを実行（初回のみ）
./setup.sh
```

セットアップスクリプトは以下を自動で行います：
- Python仮想環境の作成
- バックエンドの依存関係インストール
- フロントエンドの依存関係インストール

### 2. アプリケーションの起動

```bash
# 起動（バックエンドとフロントエンドを同時起動）
./start.sh
```

起動後、ブラウザで以下にアクセス：
- フロントエンド: http://localhost:5173
- バックエンドAPI: http://localhost:8002

### 3. アプリケーションの停止

```bash
# 停止
./stop.sh
```

## 使い方

1. **PDFファイルをアップロード**
   - 画面中央のドロップゾーンにPDFをドラッグ&ドロップ

2. **翻訳品質を選択**
   - 高品質: Qwen3-14B（最高品質、遅い）
   - バランス: Qwen2.5-7B（推奨、バランス良好）
   - 高速: Qwen2.5-3B（高速、品質やや劣る）

3. **翻訳を開始**
   - 「翻訳を開始」ボタンをクリック
   - 進捗バーで翻訳状態を確認

4. **結果を確認**
   - 左側: PDFビューア
   - 右側: 翻訳結果

5. **校正機能（オプション）**
   - 翻訳結果画面の「✓ 校正」ボタンをクリック
   - LLMが翻訳の問題点を指摘・修正

6. **用語集管理（オプション）**
   - 画面右下の用語集パネルから専門用語を追加
   - 再起動後も用語集は保持されます

7. **ダウンロード**
   - 「ダウンロード」セクションで形式を選択
   - 現在のページまたは全ページをダウンロード

## プロジェクト構成

```
PDF_Translation_App/
├── backend/                  # FastAPI バックエンド
│   ├── main.py              # メインAPI
│   ├── translator.py        # 翻訳エンジン
│   ├── requirements.txt     # Python依存関係
│   └── data/
│       └── glossary.json    # 用語集（自動生成）
├── frontend/                # React フロントエンド
│   ├── src/
│   │   ├── App.tsx          # メインアプリ
│   │   ├── api.ts           # API通信
│   │   └── components/      # コンポーネント
│   └── package.json         # Node依存関係
├── logs/                    # ログファイル（自動生成）
│   ├── backend.log
│   └── frontend.log
├── start.sh                 # 起動スクリプト
├── stop.sh                  # 停止スクリプト
└── setup.sh                 # セットアップスクリプト
```

## パフォーマンス最適化

### 実装済み最適化
- **KV Cache**: 生成速度を15-30%向上
- **torch.compile()**: JITコンパイルで高速化
- **torch.inference_mode()**: 推論モード最適化
- **float16精度**: メモリ使用量を削減

### メモリ使用量（目安）
- 高品質(14B): ~28GB
- バランス(7B): ~14GB
- 高速(3B): ~6GB

## トラブルシューティング

### ポートが既に使用されている
```bash
# ポート8002を使用しているプロセスを確認
lsof -ti:8002

# プロセスを停止
./stop.sh
```

### モデルのダウンロードが遅い
初回起動時、Hugging Faceからモデルをダウンロードします（数GB）。
ネットワーク環境により時間がかかる場合があります。

### メモリ不足エラー
- より小さいモデル（高速モード）を使用
- 他のアプリケーションを終了してメモリを確保

### 翻訳が中国語になる
- Qwen2.5-3B（高速モード）で発生しやすい
- バランスまたは高品質モードを使用してください

## ライセンス

MIT License

## 作者

babasaki-r

## 貢献

プルリクエストを歓迎します。大きな変更の場合は、まずissueを開いて変更内容を議論してください。
